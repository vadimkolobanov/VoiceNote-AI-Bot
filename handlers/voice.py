# handlers/voice.py
import logging
from datetime import datetime

from aiogram import F, Router, types
from aiogram.fsm.context import FSMContext
from aiogram.utils.markdown import hcode, hbold, hitalic

import database_setup as db  # <-- –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º db
from config import (
    MIN_VOICE_DURATION_SEC, DEEPSEEK_API_KEY_EXISTS, YANDEX_STT_CONFIGURED,
    MIN_STT_TEXT_CHARS, MIN_STT_TEXT_WORDS
)
from inline_keyboards import get_note_confirmation_keyboard
from llm_processor import enhance_text_with_llm
from services.common import get_or_create_user, check_and_update_stt_limit, increment_stt_recognition_count
from states import NoteCreationStates
from utills import download_audio_content, recognize_speech_yandex

logger = logging.getLogger(__name__)
router = Router()


@router.message(F.voice)
async def handle_voice_message(message: types.Message, state: FSMContext):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Ö–æ–¥—è—â–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è."""
    user_profile = await get_or_create_user(message.from_user)
    user_tg = message.from_user

    can_recognize, remaining_recognitions = await check_and_update_stt_limit(user_tg.id)
    if not can_recognize:
        logger.info(f"User {user_tg.id} exceeded daily STT limit.")
        await message.reply(
            "–í—ã –¥–æ—Å—Ç–∏–≥–ª–∏ –¥–Ω–µ–≤–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞ –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π. üòî\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞ –∑–∞–≤—Ç—Ä–∞. –°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–Ω–∏–º–∞–Ω–∏–µ!"
        )
        return

    voice = message.voice
    if voice.duration < MIN_VOICE_DURATION_SEC:
        logger.info(f"User {message.from_user.id} sent too short voice: {voice.duration}s")
        await message.reply(
            f"üé§ –í–∞—à–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ ({voice.duration} —Å–µ–∫.).\n"
            f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –Ω–µ –º–µ–Ω–µ–µ {MIN_VOICE_DURATION_SEC} —Å–µ–∫."
        )
        return

    file_id = voice.file_id
    voice_message_datetime = message.date
    status_msg = await message.reply("‚úîÔ∏è –ó–∞–ø–∏—Å—å –ø–æ–ª—É—á–µ–Ω–∞. –°–∫–∞—á–∏–≤–∞—é –∏ –Ω–∞—á–∏–Ω–∞—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ...")

    try:
        file_info = await message.bot.get_file(file_id)
        file_url = f"https://api.telegram.org/file/bot{message.bot.token}/{file_info.file_path}"
    except Exception as e:
        logger.exception(f"Error getting file info for user {message.from_user.id}")
        await status_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ –æ—Ç Telegram: {e}")
        return

    audio_bytes = await download_audio_content(file_url)
    if not audio_bytes:
        await status_msg.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∞—É–¥–∏–æ—Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
        return

    if not YANDEX_STT_CONFIGURED:
        await status_msg.edit_text("‚ùå –°–µ—Ä–≤–∏—Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
        logger.error("Yandex STT not configured, but voice message received.")
        return

    raw_text_stt = await recognize_speech_yandex(audio_bytes)

    if not raw_text_stt or not raw_text_stt.strip():
        logger.info(f"Yandex STT for user {message.from_user.id} returned empty text.")
        await status_msg.edit_text(
            "‚ùå –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å –≤ –≤–∞—à–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏.\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å –µ–≥–æ —á–µ—Ç—á–µ –∏–ª–∏ –≤ –±–æ–ª–µ–µ —Ç–∏—Ö–æ–º –º–µ—Å—Ç–µ."
        )
        return

    await increment_stt_recognition_count(user_tg.id)
    logger.info(f"STT successful for user {user_tg.id}. Remaining for today: {remaining_recognitions - 1}")

    if len(raw_text_stt.strip()) < MIN_STT_TEXT_CHARS or len(raw_text_stt.strip().split()) < MIN_STT_TEXT_WORDS:
        logger.info(f"Yandex STT for user {message.from_user.id} returned too short text: '{raw_text_stt}'")
        await status_msg.edit_text(
            f"‚ùå –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π.\n–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {hcode(raw_text_stt)}\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
        )
        return

    await status_msg.edit_text(
        f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ (Yandex STT):\n{hcode(raw_text_stt)}\n\n"
        "‚ú® –£–ª—É—á—à–∞—é —Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ–∫–∞—é –¥–µ—Ç–∞–ª–∏ —Å –ø–æ–º–æ—â—å—é LLM..."
    )

    llm_analysis_result_json = None
    corrected_text_for_response = raw_text_stt
    llm_info_for_user_display = ""

    if DEEPSEEK_API_KEY_EXISTS:
        # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ü–æ–ª—É—á–∞–µ–º —Ç–∞–π–º–∑–æ–Ω—É –∏ –ø–µ—Ä–µ–¥–∞–µ–º –≤ LLM ---
        user_timezone = user_profile.get('timezone', 'UTC')
        llm_result_dict = await enhance_text_with_llm(raw_text_stt, user_timezone=user_timezone)

        if "error" in llm_result_dict:
            logger.error(f"LLM error for user {message.from_user.id}: {llm_result_dict['error']}")
            llm_info_for_user_display = f"\n\n‚ö†Ô∏è {hbold('–û—à–∏–±–∫–∞ –ø—Ä–∏ AI –∞–Ω–∞–ª–∏–∑–µ:')} {hcode(llm_result_dict['error'])}"
        else:
            llm_analysis_result_json = llm_result_dict
            corrected_text_for_response = llm_result_dict.get("corrected_text", raw_text_stt)

            details_parts = [f"{hbold('‚ú® –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (AI):')}\n{hcode(corrected_text_for_response)}"]
            if llm_result_dict.get("task_description"):
                details_parts.append(f"üìù {hbold('–ó–∞–¥–∞—á–∞:')} {hitalic(llm_result_dict['task_description'])}")

            dates_times_str_list = []
            for dt_entry in llm_result_dict.get("dates_times", []):
                mention = dt_entry.get('original_mention', 'N/A')
                start_dt = dt_entry.get('absolute_datetime_start', 'N/A')
                dates_times_str_list.append(f"- {hitalic(mention)} -> {hcode(start_dt)}")
            if dates_times_str_list:
                details_parts.append(f"üóìÔ∏è {hbold('–î–∞—Ç—ã/–í—Ä–µ–º—è:')}\n" + "\n".join(dates_times_str_list))

            if llm_result_dict.get("people_mentioned"):
                details_parts.append(f"üë• {hbold('–õ—é–¥–∏:')} {hitalic(', '.join(llm_result_dict['people_mentioned']))}")
            if llm_result_dict.get("locations_mentioned"):
                details_parts.append(
                    f"üìç {hbold('–ú–µ—Å—Ç–∞:')} {hitalic(', '.join(llm_result_dict['locations_mentioned']))}")

            llm_info_for_user_display = "\n\n" + "\n\n".join(details_parts)
    else:
        llm_info_for_user_display = f"\n\n{hitalic('AI –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–ø—É—â–µ–Ω (–∫–ª—é—á API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω).')}"

    await state.set_state(NoteCreationStates.awaiting_confirmation)
    await state.update_data(
        original_stt_text=raw_text_stt,
        corrected_text_for_save=corrected_text_for_response,
        llm_analysis_json=llm_analysis_result_json,
        original_audio_telegram_file_id=file_id,
        voice_message_date=voice_message_datetime
    )

    response_to_user = (
        f"{hbold('üéôÔ∏è –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç (STT):')}\n{hcode(raw_text_stt)}"
        f"{llm_info_for_user_display}\n\n"
        f"{hbold('üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—É–¥–∏–æ:')}\n"
        f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {voice.duration} —Å–µ–∫, –†–∞–∑–º–µ—Ä: {voice.file_size // 1024} –ö–ë\n\n"
        "üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç—Ç—É –∑–∞–º–µ—Ç–∫—É?"
    )

    try:
        await status_msg.edit_text(
            response_to_user,
            reply_markup=get_note_confirmation_keyboard(),
            parse_mode="HTML"
        )
    except Exception as e:
        logger.warning(f"Could not edit status message, sending new: {e}")
        await message.answer(
            response_to_user,
            reply_markup=get_note_confirmation_keyboard(),
            parse_mode="HTML"
        )